{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ffcad75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright 2021 Google LLC\n",
    "# Use of this source code is governed by an MIT-style\n",
    "# license that can be found in the LICENSE file or at\n",
    "# https://opensource.org/licenses/MIT.\n",
    "# Notebook authors: Kevin P. Murphy (murphyk@gmail.com)\n",
    "# and Mahmoud Soliman (mjs@aucegypt.edu)\n",
    "\n",
    "# This notebook reproduces figures for chapter 19 from the book\n",
    "# \"Probabilistic Machine Learning: An Introduction\"\n",
    "# by Kevin Murphy (MIT Press, 2021).\n",
    "# Book pdf is available from http://probml.ai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56ff2d88",
   "metadata": {},
   "source": [
    "<a href=\"https://opensource.org/licenses/MIT\" target=\"_parent\"><img src=\"https://img.shields.io/github/license/probml/pyprobml\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77f3ca16",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/probml/pml-book/blob/main/pml1/figure_notebooks/chapter19_learning_with_fewer_labeled_examples_figures.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec801c97",
   "metadata": {},
   "source": [
    "## Figure 19.1:<a name='19.1'></a> <a name='cat-crops'></a> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0276bb9",
   "metadata": {},
   "source": [
    "\n",
    " Illustration of random crops and zooms of a image images. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c240c916",
   "metadata": {},
   "source": [
    "To reproduce this figure, click the open in colab button: <a href=\"https://colab.research.google.com/github/probml/probml-notebooks/blob/master/notebooks/image_augmentation_torch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d5aa72e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Click me to run setup { display-mode: \"form\" }\n",
    "try:\n",
    "  if PYPROBML_SETUP_ALREADY_RUN:\n",
    "    print('skipping setup')\n",
    "except:\n",
    "  PYPROBML_SETUP_ALREADY_RUN = True\n",
    "  print('running setup...')\n",
    "  !git clone --depth 1 https://github.com/probml/pyprobml  /pyprobml &> /dev/null \n",
    "  %cd -q /pyprobml/scripts\n",
    "  %reload_ext autoreload \n",
    "  %autoreload 2\n",
    "  !pip install superimport deimport -qqq\n",
    "  import superimport\n",
    "  from deimport.deimport import deimport\n",
    "  print('finished!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c02a149e",
   "metadata": {},
   "source": [
    "<img src=\"https://raw.githubusercontent.com/probml/pml-book/main/pml1/figures/images/Figure_19.1.png\" width=\"256\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71cfd8a5",
   "metadata": {},
   "source": [
    "## Figure 19.2:<a name='19.2'></a> <a name='transfer'></a> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "084a064b",
   "metadata": {},
   "source": [
    "\n",
    " Illustration of fine-tuning a model on a new dataset. The final output layer is trained from scratch, since it might correspond to a different label set. The other layers are initialized at their previous parameters, and then optionally updated using a small learning rate. From Figure 13.2.1 of <a href='#dive'>[Zha+20]</a> . Used with kind permission of Aston Zhang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d5aa72e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Click me to run setup { display-mode: \"form\" }\n",
    "try:\n",
    "  if PYPROBML_SETUP_ALREADY_RUN:\n",
    "    print('skipping setup')\n",
    "except:\n",
    "  PYPROBML_SETUP_ALREADY_RUN = True\n",
    "  print('running setup...')\n",
    "  !git clone --depth 1 https://github.com/probml/pyprobml  /pyprobml &> /dev/null \n",
    "  %cd -q /pyprobml/scripts\n",
    "  %reload_ext autoreload \n",
    "  %autoreload 2\n",
    "  !pip install superimport deimport -qqq\n",
    "  import superimport\n",
    "  from deimport.deimport import deimport\n",
    "  print('finished!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "676656f0",
   "metadata": {},
   "source": [
    "<img src=\"https://raw.githubusercontent.com/probml/pml-book/main/pml1/figures/images/Figure_19.2.png\" width=\"256\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "612f2876",
   "metadata": {},
   "source": [
    "## Figure 19.3:<a name='19.3'></a> <a name='adapters'></a> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba4fd163",
   "metadata": {},
   "source": [
    "\n",
    "(a) Adding adapter layers to a transformer. From Figure 2 of <a href='#Houlsby2019'>[Nei+19]</a> . Used with kind permission of Neil Houlsby. (b) Adding adapter layers to a resnet. From Figure 2 of <a href='#Rebuffi2018'>[SHA18]</a> . Used with kind permission of Sylvestre-Alvise Rebuffi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d5aa72e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Click me to run setup { display-mode: \"form\" }\n",
    "try:\n",
    "  if PYPROBML_SETUP_ALREADY_RUN:\n",
    "    print('skipping setup')\n",
    "except:\n",
    "  PYPROBML_SETUP_ALREADY_RUN = True\n",
    "  print('running setup...')\n",
    "  !git clone --depth 1 https://github.com/probml/pyprobml  /pyprobml &> /dev/null \n",
    "  %cd -q /pyprobml/scripts\n",
    "  %reload_ext autoreload \n",
    "  %autoreload 2\n",
    "  !pip install superimport deimport -qqq\n",
    "  import superimport\n",
    "  from deimport.deimport import deimport\n",
    "  print('finished!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a5fbc4e",
   "metadata": {},
   "source": [
    "<img src=\"https://raw.githubusercontent.com/probml/pml-book/main/pml1/figures/images/Figure_19.3_A.png\" width=\"256\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "542c1a87",
   "metadata": {},
   "source": [
    "<img src=\"https://raw.githubusercontent.com/probml/pml-book/main/pml1/figures/images/Figure_19.3_B.png\" width=\"256\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cf807fd",
   "metadata": {},
   "source": [
    "## Figure 19.4:<a name='19.4'></a> <a name='supervisedImputation'></a> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b29c42f0",
   "metadata": {},
   "source": [
    "\n",
    "(a) Context encoder for self-supervised learning. From <a href='#Pathak2016'>[Dee+16]</a> . Used with kind permission of Deepak Pathak. (b) Some other proxy tasks for self-supervised learning. From <a href='#LeCunSSL2018'>[LeC18]</a> . Used with kind permission of Yann LeCun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d5aa72e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Click me to run setup { display-mode: \"form\" }\n",
    "try:\n",
    "  if PYPROBML_SETUP_ALREADY_RUN:\n",
    "    print('skipping setup')\n",
    "except:\n",
    "  PYPROBML_SETUP_ALREADY_RUN = True\n",
    "  print('running setup...')\n",
    "  !git clone --depth 1 https://github.com/probml/pyprobml  /pyprobml &> /dev/null \n",
    "  %cd -q /pyprobml/scripts\n",
    "  %reload_ext autoreload \n",
    "  %autoreload 2\n",
    "  !pip install superimport deimport -qqq\n",
    "  import superimport\n",
    "  from deimport.deimport import deimport\n",
    "  print('finished!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "477f3652",
   "metadata": {},
   "source": [
    "<img src=\"https://raw.githubusercontent.com/probml/pml-book/main/pml1/figures/images/Figure_19.4_A.png\" width=\"256\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3708cc93",
   "metadata": {},
   "source": [
    "<img src=\"https://raw.githubusercontent.com/probml/pml-book/main/pml1/figures/images/Figure_19.4_B.png\" width=\"256\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6866e31b",
   "metadata": {},
   "source": [
    "## Figure 19.5:<a name='19.5'></a> <a name='simCLRcrop'></a> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85a56af4",
   "metadata": {},
   "source": [
    "\n",
    "(a) Illustration of SimCLR training. $\\mathcal T $ is a set of stochastic semantics-preserving transformations (data augmentations). (b-c) Illustration of the benefit of random crops. Solid rectangles represent the original image, dashed rectangles are random crops. In (b), the model is forced to predict the local view A from the global view B (and vice versa). In (c), the model is forced to predict the appearance of adjacent views (C,D). From Figures 2--3 of <a href='#chen2020simple'>[Tin+20]</a> . Used with kind permission of Ting Chen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d5aa72e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Click me to run setup { display-mode: \"form\" }\n",
    "try:\n",
    "  if PYPROBML_SETUP_ALREADY_RUN:\n",
    "    print('skipping setup')\n",
    "except:\n",
    "  PYPROBML_SETUP_ALREADY_RUN = True\n",
    "  print('running setup...')\n",
    "  !git clone --depth 1 https://github.com/probml/pyprobml  /pyprobml &> /dev/null \n",
    "  %cd -q /pyprobml/scripts\n",
    "  %reload_ext autoreload \n",
    "  %autoreload 2\n",
    "  !pip install superimport deimport -qqq\n",
    "  import superimport\n",
    "  from deimport.deimport import deimport\n",
    "  print('finished!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f6fae45",
   "metadata": {},
   "source": [
    "## Figure 19.6:<a name='19.6'></a> <a name='simCLR'></a> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c383fd75",
   "metadata": {},
   "source": [
    "\n",
    " Visualization of SimCLR training. Each input image in the minibatch is randomly modified in two different ways (using cropping (followed by resize), flipping, and color distortion), and then fed into a Siamese network. The embeddings (final layer) for each pair derived from the same image is forced to be close, whereas the embeddings for all other pairs are forced to be far. From  https://ai.googleblog.com/2020/04/advancing-self-supervised-and-semi.html . Used with kind permission of Ting Chen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d5aa72e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Click me to run setup { display-mode: \"form\" }\n",
    "try:\n",
    "  if PYPROBML_SETUP_ALREADY_RUN:\n",
    "    print('skipping setup')\n",
    "except:\n",
    "  PYPROBML_SETUP_ALREADY_RUN = True\n",
    "  print('running setup...')\n",
    "  !git clone --depth 1 https://github.com/probml/pyprobml  /pyprobml &> /dev/null \n",
    "  %cd -q /pyprobml/scripts\n",
    "  %reload_ext autoreload \n",
    "  %autoreload 2\n",
    "  !pip install superimport deimport -qqq\n",
    "  import superimport\n",
    "  from deimport.deimport import deimport\n",
    "  print('finished!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c6f81ca",
   "metadata": {},
   "source": [
    "<img src=\"https://raw.githubusercontent.com/probml/pml-book/main/pml1/figures/images/Figure_19.6_A.png\" width=\"256\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b00b6db7",
   "metadata": {},
   "source": [
    "<img src=\"https://raw.githubusercontent.com/probml/pml-book/main/pml1/figures/images/Figure_19.6_B.png\" width=\"256\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e4c5a02",
   "metadata": {},
   "source": [
    "## Figure 19.7:<a name='19.7'></a> <a name='CLIP'></a> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20ca1d73",
   "metadata": {},
   "source": [
    "\n",
    " Illustration of the CLIP model. From Figure 1 of <a href='#CLIP'>[Ale+]</a> . Used with kind permission of Alec Radford"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d5aa72e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Click me to run setup { display-mode: \"form\" }\n",
    "try:\n",
    "  if PYPROBML_SETUP_ALREADY_RUN:\n",
    "    print('skipping setup')\n",
    "except:\n",
    "  PYPROBML_SETUP_ALREADY_RUN = True\n",
    "  print('running setup...')\n",
    "  !git clone --depth 1 https://github.com/probml/pyprobml  /pyprobml &> /dev/null \n",
    "  %cd -q /pyprobml/scripts\n",
    "  %reload_ext autoreload \n",
    "  %autoreload 2\n",
    "  !pip install superimport deimport -qqq\n",
    "  import superimport\n",
    "  from deimport.deimport import deimport\n",
    "  print('finished!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad060c29",
   "metadata": {},
   "source": [
    "<img src=\"https://raw.githubusercontent.com/probml/pml-book/main/pml1/figures/images/Figure_19.7_A.png\" width=\"256\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8944264",
   "metadata": {},
   "source": [
    "<img src=\"https://raw.githubusercontent.com/probml/pml-book/main/pml1/figures/images/Figure_19.7_B.png\" width=\"256\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cbd531f",
   "metadata": {},
   "source": [
    "## Figure 19.8:<a name='19.8'></a> <a name='SSL'></a> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d4aad69",
   "metadata": {},
   "source": [
    "\n",
    " Illustration of the benefits of semi-supervised learning for a binary classification problem. Labeled points from each class are shown as black and white circles respectively. (a) Decision boundary we might learn given only unlabeled data. (b) Decision boundary we might learn if we also had a lot of unlabeled data points, shown as smaller grey circles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d5aa72e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Click me to run setup { display-mode: \"form\" }\n",
    "try:\n",
    "  if PYPROBML_SETUP_ALREADY_RUN:\n",
    "    print('skipping setup')\n",
    "except:\n",
    "  PYPROBML_SETUP_ALREADY_RUN = True\n",
    "  print('running setup...')\n",
    "  !git clone --depth 1 https://github.com/probml/pyprobml  /pyprobml &> /dev/null \n",
    "  %cd -q /pyprobml/scripts\n",
    "  %reload_ext autoreload \n",
    "  %autoreload 2\n",
    "  !pip install superimport deimport -qqq\n",
    "  import superimport\n",
    "  from deimport.deimport import deimport\n",
    "  print('finished!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be240523",
   "metadata": {},
   "source": [
    "<img src=\"https://raw.githubusercontent.com/probml/pml-book/main/pml1/figures/images/Figure_19.8_A.png\" width=\"256\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ee6a29b",
   "metadata": {},
   "source": [
    "<img src=\"https://raw.githubusercontent.com/probml/pml-book/main/pml1/figures/images/Figure_19.8_B.png\" width=\"256\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ef00c9b",
   "metadata": {},
   "source": [
    "## Figure 19.9:<a name='19.9'></a> <a name='emvsst'></a> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "749cc908",
   "metadata": {},
   "source": [
    "\n",
    " Comparison of the entropy minimization, self-training, and ``sharpened'' entropy minimization loss functions for a binary classification problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d5aa72e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Click me to run setup { display-mode: \"form\" }\n",
    "try:\n",
    "  if PYPROBML_SETUP_ALREADY_RUN:\n",
    "    print('skipping setup')\n",
    "except:\n",
    "  PYPROBML_SETUP_ALREADY_RUN = True\n",
    "  print('running setup...')\n",
    "  !git clone --depth 1 https://github.com/probml/pyprobml  /pyprobml &> /dev/null \n",
    "  %cd -q /pyprobml/scripts\n",
    "  %reload_ext autoreload \n",
    "  %autoreload 2\n",
    "  !pip install superimport deimport -qqq\n",
    "  import superimport\n",
    "  from deimport.deimport import deimport\n",
    "  print('finished!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "123a9082",
   "metadata": {},
   "source": [
    "<img src=\"https://raw.githubusercontent.com/probml/pml-book/main/pml1/figures/images/Figure_19.9.png\" width=\"256\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccd70831",
   "metadata": {},
   "source": [
    "## Figure 19.10:<a name='19.10'></a> <a name='emgoodbad'></a> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af4a4a87",
   "metadata": {},
   "source": [
    "\n",
    " Visualization demonstrating how entropy minimization enforces the cluster assumption. The classifier assigns a higher probability to class 1 (black dots) or 2 (white dots) in red or blue regions respectively. The predicted class probabilities for one particular unlabeled datapoint is shown in the bar plot. In (a), the decision boundary passes through high-density regions of data, so the classifier is forced to output high-entropy predictions. In (b), the classifier avoids high-density regions and is able to assign low-entropy predictions to most of the unlabeled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d5aa72e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Click me to run setup { display-mode: \"form\" }\n",
    "try:\n",
    "  if PYPROBML_SETUP_ALREADY_RUN:\n",
    "    print('skipping setup')\n",
    "except:\n",
    "  PYPROBML_SETUP_ALREADY_RUN = True\n",
    "  print('running setup...')\n",
    "  !git clone --depth 1 https://github.com/probml/pyprobml  /pyprobml &> /dev/null \n",
    "  %cd -q /pyprobml/scripts\n",
    "  %reload_ext autoreload \n",
    "  %autoreload 2\n",
    "  !pip install superimport deimport -qqq\n",
    "  import superimport\n",
    "  from deimport.deimport import deimport\n",
    "  print('finished!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8d35e19",
   "metadata": {},
   "source": [
    "<img src=\"https://raw.githubusercontent.com/probml/pml-book/main/pml1/figures/images/Figure_19.10_A.png\" width=\"256\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9ecee9e",
   "metadata": {},
   "source": [
    "<img src=\"https://raw.githubusercontent.com/probml/pml-book/main/pml1/figures/images/Figure_19.10_B.png\" width=\"256\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30fcdf5e",
   "metadata": {},
   "source": [
    "## Figure 19.11:<a name='19.11'></a> <a name='sevskl'></a> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "749456f9",
   "metadata": {},
   "source": [
    "\n",
    " Comparison of the squared error and KL divergence lossses for a consistency regularization. This visualization is for a binary classification problem where it is assumed that the model's output for the unperturbed input is 1. The figure plots the loss incurred for a particular value of the logit (i.e.\\the pre-activation fed into the output sigmoid nonlinearity) for the perturbed input. As the logit grows towards infinity, the model predicts a class label of 1 (in agreement with the prediction for the unperturbed input); as it grows towards negative infinity, the model predictions class 0. The squared error loss saturates (and has zero gradients) when the model predicts one class or the other with high probability, but the KL divergence grows without bound as the model predicts class 0 with more and more confidence.\\rela"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d5aa72e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Click me to run setup { display-mode: \"form\" }\n",
    "try:\n",
    "  if PYPROBML_SETUP_ALREADY_RUN:\n",
    "    print('skipping setup')\n",
    "except:\n",
    "  PYPROBML_SETUP_ALREADY_RUN = True\n",
    "  print('running setup...')\n",
    "  !git clone --depth 1 https://github.com/probml/pyprobml  /pyprobml &> /dev/null \n",
    "  %cd -q /pyprobml/scripts\n",
    "  %reload_ext autoreload \n",
    "  %autoreload 2\n",
    "  !pip install superimport deimport -qqq\n",
    "  import superimport\n",
    "  from deimport.deimport import deimport\n",
    "  print('finished!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9db71e49",
   "metadata": {},
   "source": [
    "<img src=\"https://raw.githubusercontent.com/probml/pml-book/main/pml1/figures/images/Figure_19.11.png\" width=\"256\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29b670d7",
   "metadata": {},
   "source": [
    "## Figure 19.12:<a name='19.12'></a> <a name='ssgan'></a> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f59a27f",
   "metadata": {},
   "source": [
    "\n",
    " Diagram of the semi-supervised GAN framework. The discriminator is trained to output the class of labeled datapoints (red), a ``fake'' label for outputs from the generator (yellow), and any label for unlabeled data (green)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d5aa72e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Click me to run setup { display-mode: \"form\" }\n",
    "try:\n",
    "  if PYPROBML_SETUP_ALREADY_RUN:\n",
    "    print('skipping setup')\n",
    "except:\n",
    "  PYPROBML_SETUP_ALREADY_RUN = True\n",
    "  print('running setup...')\n",
    "  !git clone --depth 1 https://github.com/probml/pyprobml  /pyprobml &> /dev/null \n",
    "  %cd -q /pyprobml/scripts\n",
    "  %reload_ext autoreload \n",
    "  %autoreload 2\n",
    "  !pip install superimport deimport -qqq\n",
    "  import superimport\n",
    "  from deimport.deimport import deimport\n",
    "  print('finished!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58265746",
   "metadata": {},
   "source": [
    "<img src=\"https://raw.githubusercontent.com/probml/pml-book/main/pml1/figures/images/Figure_19.12.png\" width=\"256\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "716515af",
   "metadata": {},
   "source": [
    "## Figure 19.13:<a name='19.13'></a> <a name='SimCLR2'></a> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baa1a6ed",
   "metadata": {},
   "source": [
    "\n",
    " Combining self-supervised learning on unlabeled data (left), supervised fine-tuning (middle), and self-training on pseudo-labeled data (right). From Figure 3 of <a href='#Chen2020nips'>[Tin+20]</a> . Used with kind permission of Ting Chen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d5aa72e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Click me to run setup { display-mode: \"form\" }\n",
    "try:\n",
    "  if PYPROBML_SETUP_ALREADY_RUN:\n",
    "    print('skipping setup')\n",
    "except:\n",
    "  PYPROBML_SETUP_ALREADY_RUN = True\n",
    "  print('running setup...')\n",
    "  !git clone --depth 1 https://github.com/probml/pyprobml  /pyprobml &> /dev/null \n",
    "  %cd -q /pyprobml/scripts\n",
    "  %reload_ext autoreload \n",
    "  %autoreload 2\n",
    "  !pip install superimport deimport -qqq\n",
    "  import superimport\n",
    "  from deimport.deimport import deimport\n",
    "  print('finished!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b1310e5",
   "metadata": {},
   "source": [
    "<img src=\"https://raw.githubusercontent.com/probml/pml-book/main/pml1/figures/images/Figure_19.13.png\" width=\"256\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7393858",
   "metadata": {},
   "source": [
    "## Figure 19.14:<a name='19.14'></a> <a name='MAML-PGM'></a> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c0c28f6",
   "metadata": {},
   "source": [
    "\n",
    " Graphical model corresponding to MAML. Left: generative model. Right: During meta-training, each of the task parameters $ \\bm \\theta   _j$'s are updated using their local datasets. The indices $j$ are over tasks (meta datasets), and $i$ are over instances within each task. Solid shaded nodes are always observed; semi-shaded (striped) nodes are only observed during meta training time (i.e., not at test time). From Figure 1 of <a href='#Finn2018'>[CKS18]</a> . Used with kind permission of Chelsea Finn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d5aa72e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Click me to run setup { display-mode: \"form\" }\n",
    "try:\n",
    "  if PYPROBML_SETUP_ALREADY_RUN:\n",
    "    print('skipping setup')\n",
    "except:\n",
    "  PYPROBML_SETUP_ALREADY_RUN = True\n",
    "  print('running setup...')\n",
    "  !git clone --depth 1 https://github.com/probml/pyprobml  /pyprobml &> /dev/null \n",
    "  %cd -q /pyprobml/scripts\n",
    "  %reload_ext autoreload \n",
    "  %autoreload 2\n",
    "  !pip install superimport deimport -qqq\n",
    "  import superimport\n",
    "  from deimport.deimport import deimport\n",
    "  print('finished!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d42fb076",
   "metadata": {},
   "source": [
    "<img src=\"https://raw.githubusercontent.com/probml/pml-book/main/pml1/figures/images/Figure_19.14.png\" width=\"256\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4491c6e3",
   "metadata": {},
   "source": [
    "## Figure 19.15:<a name='19.15'></a> <a name='metaLearningFSL'></a> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdc70496",
   "metadata": {},
   "source": [
    "\n",
    " Illustration of meta-learning for few-shot learning. Here, each task is a 3-way-2-shot classification problem because each training task contains a support set with three classes, each with two examples. From  https://bit.ly/3rrvSjw . Copyright (2019) Borealis AI. Used with kind permission of Simon Prince and April Cooper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d5aa72e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Click me to run setup { display-mode: \"form\" }\n",
    "try:\n",
    "  if PYPROBML_SETUP_ALREADY_RUN:\n",
    "    print('skipping setup')\n",
    "except:\n",
    "  PYPROBML_SETUP_ALREADY_RUN = True\n",
    "  print('running setup...')\n",
    "  !git clone --depth 1 https://github.com/probml/pyprobml  /pyprobml &> /dev/null \n",
    "  %cd -q /pyprobml/scripts\n",
    "  %reload_ext autoreload \n",
    "  %autoreload 2\n",
    "  !pip install superimport deimport -qqq\n",
    "  import superimport\n",
    "  from deimport.deimport import deimport\n",
    "  print('finished!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a67fc714",
   "metadata": {},
   "source": [
    "<img src=\"https://raw.githubusercontent.com/probml/pml-book/main/pml1/figures/images/Figure_19.15.png\" width=\"256\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cff9dac3",
   "metadata": {},
   "source": [
    "## Figure 19.16:<a name='19.16'></a> <a name='matchingNetworks'></a> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3c5f1e1",
   "metadata": {},
   "source": [
    "\n",
    " Illustration of a matching network for one-shot learning. From Figure 1 of <a href='#Vinyals2016'>[Ori+16]</a> . Used with kind permission of Oriol Vinyals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d5aa72e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Click me to run setup { display-mode: \"form\" }\n",
    "try:\n",
    "  if PYPROBML_SETUP_ALREADY_RUN:\n",
    "    print('skipping setup')\n",
    "except:\n",
    "  PYPROBML_SETUP_ALREADY_RUN = True\n",
    "  print('running setup...')\n",
    "  !git clone --depth 1 https://github.com/probml/pyprobml  /pyprobml &> /dev/null \n",
    "  %cd -q /pyprobml/scripts\n",
    "  %reload_ext autoreload \n",
    "  %autoreload 2\n",
    "  !pip install superimport deimport -qqq\n",
    "  import superimport\n",
    "  from deimport.deimport import deimport\n",
    "  print('finished!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17535bd6",
   "metadata": {},
   "source": [
    "<img src=\"https://raw.githubusercontent.com/probml/pml-book/main/pml1/figures/images/Figure_19.16.png\" width=\"256\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71535b8b",
   "metadata": {},
   "source": [
    "## References:\n",
    " <a name='CLIP'>[Ale+]</a> R. Alec, K. JongWook, H. Chris, R. Aditya, G. Gabriel, A. Sandhini, S. Girish, A. Amanda, M. Pamela, C. Jack, K. Gretchen and S. Ilya. \"Learning transferable visual models from natural languagesupervision\". \n",
    "\n",
    "<a name='Finn2018'>[CKS18]</a> F. Chelsea, X. Kelvin and L. Sergey. \"Probabilistic Model-Agnostic Meta-Learning\". (2018). \n",
    "\n",
    "<a name='Pathak2016'>[Dee+16]</a> P. Deepak, K. Philipp, D. Jeff, D. Trevor and E. AlexeiA. \"Context Encoders: Feature Learning by Inpainting\". (2016). \n",
    "\n",
    "<a name='LeCunSSL2018'>[LeC18]</a> Y. LeCun \"Self-supervised learning: could machines learn like humans?\". (2018). \n",
    "\n",
    "<a name='Houlsby2019'>[Nei+19]</a> H. Neil, G. Andrei, J. Stanislaw, M. Bruna, d. Quentin, G. A. Mona and G. Sylvain. \"Parameter-Efficient Transfer Learning for NLP\". (2019). \n",
    "\n",
    "<a name='Vinyals2016'>[Ori+16]</a> V. Oriol, B. Charles, L. Timothy, K. Koray and W. Daan. \"Matching Networks for One Shot Learning\". (2016). \n",
    "\n",
    "<a name='Rebuffi2018'>[SHA18]</a> R. Sylvestre-Alvise, B. Hakan and V. Andrea. \"Efficient parametrization of multi-domain deep neural networks\". (2018). \n",
    "\n",
    "<a name='Chen2020nips'>[Tin+20]</a> C. Ting, K. Simon, S. Kevin, N. NorouziMohammad and H. Geoffrey. \"Big Self-Supervised Models are Strong Semi-SupervisedLearners\". (2020). \n",
    "\n",
    "<a name='dive'>[Zha+20]</a> A. Zhang, Z. Lipton, M. Li and A. Smola. \"Dive into deep learning\". (2020). \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
