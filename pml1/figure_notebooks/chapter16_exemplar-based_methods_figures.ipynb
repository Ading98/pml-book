{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd2e1ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright 2021 Google LLC\n",
    "# Use of this source code is governed by an MIT-style\n",
    "# license that can be found in the LICENSE file or at\n",
    "# https://opensource.org/licenses/MIT.\n",
    "# Notebook authors: Kevin P. Murphy (murphyk@gmail.com)\n",
    "# and Mahmoud Soliman (mjs@aucegypt.edu)\n",
    "\n",
    "# This notebook reproduces figures for chapter 16 from the book\n",
    "# \"Probabilistic Machine Learning: An Introduction\"\n",
    "# by Kevin Murphy (MIT Press, 2021).\n",
    "# Book pdf is available from http://probml.ai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "398085af",
   "metadata": {},
   "source": [
    "<a href=\"https://opensource.org/licenses/MIT\" target=\"_parent\"><img src=\"https://img.shields.io/github/license/probml/pyprobml\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cd08bbf",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/probml/pml-book/blob/main/pml1/figure_notebooks/chapter16_exemplar-based_methods_figures.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a8385bf",
   "metadata": {},
   "source": [
    "## Figure 16.1:<a name='16.1'></a> <a name='knn'></a> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ea0c3be",
   "metadata": {},
   "source": [
    "\n",
    "(a) Illustration of a $K$-nearest neighbors classifier in 2d for $K=5$. The nearest neighbors of test point $ \\bm x  $ have labels $\\ 1, 1, 1, 0, 0\\ $, so we predict $p(y=1| \\bm x  , \\mathcal D  ) = 3/5$. (b) Illustration of the Voronoi tesselation induced by 1-NN. Adapted from Figure 4.13 of <a href='#Duda01'>[DHS01]</a> .  \n",
    "Figure(s) generated by [knn_voronoi_plot.py](https://github.com/probml/pyprobml/blob/master/scripts/knn_voronoi_plot.py) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcff7632",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Click me to run setup { display-mode: \"form\" }\n",
    "try:\n",
    "  if PYPROBML_SETUP_ALREADY_RUN:\n",
    "    print('skipping setup')\n",
    "except:\n",
    "  PYPROBML_SETUP_ALREADY_RUN = True\n",
    "  print('running setup...')\n",
    "  !git clone --depth 1 https://github.com/probml/pyprobml  /pyprobml &> /dev/null \n",
    "  %cd -q /pyprobml/scripts\n",
    "  import pyprobml_utils as pml\n",
    "  import colab_utils\n",
    "  import os\n",
    "  os.environ[\"PYPROBML\"] = \"..\" # one above current scripts directory\n",
    "  import google.colab \n",
    "  from google.colab.patches import cv2_imshow\n",
    "  %reload_ext autoreload \n",
    "  %autoreload 2\n",
    "  print('finished!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec8934a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run knn_voronoi_plot.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03bdc2d7",
   "metadata": {},
   "source": [
    "## Figure 16.2:<a name='16.2'></a> <a name='knnThreeClass'></a> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20c9c7f3",
   "metadata": {},
   "source": [
    "\n",
    " Decision boundaries induced by a KNN classifier. (a) $K=1$. (b) $K=2$. (c) $K=5$. (d) Train and test error vs $K$.  \n",
    "Figure(s) generated by [knn_classify_demo.py](https://github.com/probml/pyprobml/blob/master/scripts/knn_classify_demo.py) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcff7632",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Click me to run setup { display-mode: \"form\" }\n",
    "try:\n",
    "  if PYPROBML_SETUP_ALREADY_RUN:\n",
    "    print('skipping setup')\n",
    "except:\n",
    "  PYPROBML_SETUP_ALREADY_RUN = True\n",
    "  print('running setup...')\n",
    "  !git clone --depth 1 https://github.com/probml/pyprobml  /pyprobml &> /dev/null \n",
    "  %cd -q /pyprobml/scripts\n",
    "  import pyprobml_utils as pml\n",
    "  import colab_utils\n",
    "  import os\n",
    "  os.environ[\"PYPROBML\"] = \"..\" # one above current scripts directory\n",
    "  import google.colab \n",
    "  from google.colab.patches import cv2_imshow\n",
    "  %reload_ext autoreload \n",
    "  %autoreload 2\n",
    "  print('finished!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15f06dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run knn_classify_demo.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "232c71a3",
   "metadata": {},
   "source": [
    "## Figure 16.3:<a name='16.3'></a> <a name='curse'></a> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec9340df",
   "metadata": {},
   "source": [
    "\n",
    " Illustration of the curse of dimensionality. (a) We embed a small cube of side $s$ inside a larger unit cube. (b) We plot the edge length of a cube needed to cover a given volume of the unit cube as a function of the number of dimensions. Adapted from Figure 2.6 from <a href='#HastieBook'>[HTF09]</a> .  \n",
    "Figure(s) generated by [curse_dimensionality_plot.py](https://github.com/probml/pyprobml/blob/master/scripts/curse_dimensionality_plot.py) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcff7632",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Click me to run setup { display-mode: \"form\" }\n",
    "try:\n",
    "  if PYPROBML_SETUP_ALREADY_RUN:\n",
    "    print('skipping setup')\n",
    "except:\n",
    "  PYPROBML_SETUP_ALREADY_RUN = True\n",
    "  print('running setup...')\n",
    "  !git clone --depth 1 https://github.com/probml/pyprobml  /pyprobml &> /dev/null \n",
    "  %cd -q /pyprobml/scripts\n",
    "  import pyprobml_utils as pml\n",
    "  import colab_utils\n",
    "  import os\n",
    "  os.environ[\"PYPROBML\"] = \"..\" # one above current scripts directory\n",
    "  import google.colab \n",
    "  from google.colab.patches import cv2_imshow\n",
    "  %reload_ext autoreload \n",
    "  %autoreload 2\n",
    "  print('finished!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb956dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run curse_dimensionality_plot.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e2a726c",
   "metadata": {},
   "source": [
    "## Figure 16.4:<a name='16.4'></a> <a name='LCA'></a> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65247dd6",
   "metadata": {},
   "source": [
    "\n",
    " Illustration of latent coincidence analysis (LCA) as a directed graphical model. The inputs $ \\bm x  ,  \\bm x  ' \\in \\mathbb R ^D$ are mapped into Gaussian latent variables $ \\bm z  ,  \\bm z  ' \\in \\mathbb R ^L$ via a linear mapping $\\mathbf W $. If the two latent points coincide (within length scale $\\kappa $) then we set the similarity label to $y=1$, otherwise we set it to $y=0$. From Figure 1 of <a href='#Der2012'>[ML12]</a> . Used with kind permission of Lawrence Saul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcff7632",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Click me to run setup { display-mode: \"form\" }\n",
    "try:\n",
    "  if PYPROBML_SETUP_ALREADY_RUN:\n",
    "    print('skipping setup')\n",
    "except:\n",
    "  PYPROBML_SETUP_ALREADY_RUN = True\n",
    "  print('running setup...')\n",
    "  !git clone --depth 1 https://github.com/probml/pyprobml  /pyprobml &> /dev/null \n",
    "  %cd -q /pyprobml/scripts\n",
    "  import pyprobml_utils as pml\n",
    "  import colab_utils\n",
    "  import os\n",
    "  os.environ[\"PYPROBML\"] = \"..\" # one above current scripts directory\n",
    "  import google.colab \n",
    "  from google.colab.patches import cv2_imshow\n",
    "  %reload_ext autoreload \n",
    "  %autoreload 2\n",
    "  print('finished!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d0e5245",
   "metadata": {},
   "source": [
    "<img src=\"https://github.com/probml/pml-book/raw/main/pml1/figures/Figure_16.4.png\" width=\"256\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a711ff",
   "metadata": {},
   "source": [
    "## Figure 16.5:<a name='16.5'></a> <a name='tripletNet'></a> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e033f8c",
   "metadata": {},
   "source": [
    "\n",
    " Networks for deep metric learning. (a) Siamese network. (b) Triplet network. Adapted from Figure 5 of <a href='#Kaya2019'>[MH19]</a> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcff7632",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Click me to run setup { display-mode: \"form\" }\n",
    "try:\n",
    "  if PYPROBML_SETUP_ALREADY_RUN:\n",
    "    print('skipping setup')\n",
    "except:\n",
    "  PYPROBML_SETUP_ALREADY_RUN = True\n",
    "  print('running setup...')\n",
    "  !git clone --depth 1 https://github.com/probml/pyprobml  /pyprobml &> /dev/null \n",
    "  %cd -q /pyprobml/scripts\n",
    "  import pyprobml_utils as pml\n",
    "  import colab_utils\n",
    "  import os\n",
    "  os.environ[\"PYPROBML\"] = \"..\" # one above current scripts directory\n",
    "  import google.colab \n",
    "  from google.colab.patches import cv2_imshow\n",
    "  %reload_ext autoreload \n",
    "  %autoreload 2\n",
    "  print('finished!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d936cfd",
   "metadata": {},
   "source": [
    "<img src=\"https://github.com/probml/pml-book/raw/main/pml1/figures/Figure_16.5_A.png\" width=\"256\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c2467de",
   "metadata": {},
   "source": [
    "<img src=\"https://github.com/probml/pml-book/raw/main/pml1/figures/Figure_16.5_B.png\" width=\"256\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7640173f",
   "metadata": {},
   "source": [
    "## Figure 16.6:<a name='16.6'></a> <a name='tripletBound'></a> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "205fd864",
   "metadata": {},
   "source": [
    "\n",
    " Speeding up triplet loss minimization. (a) Illustration of hard vs easy negatives. Here $a$ is the anchor point, $p$ is a positive point, and $n_i$ are negative points. Adapted from Figure 4 of <a href='#Kaya2019'>[MH19]</a> . (b) Standard triplet loss would take $8 \\times 3 \\times 4 = 96$ calculations, whereas using a proxy loss (with one proxy per class) takes $8 \\times 2 = 16$ calculations. From Figure 1 of <a href='#Do2019cvpr'>[Tha+19]</a> . Used with kind permission of Gustavo Cerneiro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcff7632",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Click me to run setup { display-mode: \"form\" }\n",
    "try:\n",
    "  if PYPROBML_SETUP_ALREADY_RUN:\n",
    "    print('skipping setup')\n",
    "except:\n",
    "  PYPROBML_SETUP_ALREADY_RUN = True\n",
    "  print('running setup...')\n",
    "  !git clone --depth 1 https://github.com/probml/pyprobml  /pyprobml &> /dev/null \n",
    "  %cd -q /pyprobml/scripts\n",
    "  import pyprobml_utils as pml\n",
    "  import colab_utils\n",
    "  import os\n",
    "  os.environ[\"PYPROBML\"] = \"..\" # one above current scripts directory\n",
    "  import google.colab \n",
    "  from google.colab.patches import cv2_imshow\n",
    "  %reload_ext autoreload \n",
    "  %autoreload 2\n",
    "  print('finished!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "359cd367",
   "metadata": {},
   "source": [
    "<img src=\"https://github.com/probml/pml-book/raw/main/pml1/figures/Figure_16.6_A.png\" width=\"256\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "317fa70f",
   "metadata": {},
   "source": [
    "<img src=\"https://github.com/probml/pml-book/raw/main/pml1/figures/Figure_16.6_B.png\" width=\"256\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "550be8ca",
   "metadata": {},
   "source": [
    "## Figure 16.7:<a name='16.7'></a> <a name='SEC'></a> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1143af53",
   "metadata": {},
   "source": [
    "\n",
    " Adding spherical embedding constraint to a deep metric learning method. Used with kind permission of Dingyi Zhang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcff7632",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Click me to run setup { display-mode: \"form\" }\n",
    "try:\n",
    "  if PYPROBML_SETUP_ALREADY_RUN:\n",
    "    print('skipping setup')\n",
    "except:\n",
    "  PYPROBML_SETUP_ALREADY_RUN = True\n",
    "  print('running setup...')\n",
    "  !git clone --depth 1 https://github.com/probml/pyprobml  /pyprobml &> /dev/null \n",
    "  %cd -q /pyprobml/scripts\n",
    "  import pyprobml_utils as pml\n",
    "  import colab_utils\n",
    "  import os\n",
    "  os.environ[\"PYPROBML\"] = \"..\" # one above current scripts directory\n",
    "  import google.colab \n",
    "  from google.colab.patches import cv2_imshow\n",
    "  %reload_ext autoreload \n",
    "  %autoreload 2\n",
    "  print('finished!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "520ba932",
   "metadata": {},
   "source": [
    "<img src=\"https://github.com/probml/pml-book/raw/main/pml1/figures/Figure_16.7.png\" width=\"256\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "784bb7fa",
   "metadata": {},
   "source": [
    "## Figure 16.8:<a name='16.8'></a> <a name='smoothingKernels'></a> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a98bc63",
   "metadata": {},
   "source": [
    "\n",
    " A comparison of some popular normalized kernels.  \n",
    "Figure(s) generated by [smoothingKernelPlot.py](https://github.com/probml/pyprobml/blob/master/scripts/smoothingKernelPlot.py) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcff7632",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Click me to run setup { display-mode: \"form\" }\n",
    "try:\n",
    "  if PYPROBML_SETUP_ALREADY_RUN:\n",
    "    print('skipping setup')\n",
    "except:\n",
    "  PYPROBML_SETUP_ALREADY_RUN = True\n",
    "  print('running setup...')\n",
    "  !git clone --depth 1 https://github.com/probml/pyprobml  /pyprobml &> /dev/null \n",
    "  %cd -q /pyprobml/scripts\n",
    "  import pyprobml_utils as pml\n",
    "  import colab_utils\n",
    "  import os\n",
    "  os.environ[\"PYPROBML\"] = \"..\" # one above current scripts directory\n",
    "  import google.colab \n",
    "  from google.colab.patches import cv2_imshow\n",
    "  %reload_ext autoreload \n",
    "  %autoreload 2\n",
    "  print('finished!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19065c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run smoothingKernelPlot.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "288656ca",
   "metadata": {},
   "source": [
    "## Figure 16.9:<a name='16.9'></a> <a name='parzen'></a> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3691e49c",
   "metadata": {},
   "source": [
    "\n",
    " A nonparametric (Parzen) density estimator in 1d estimated from 6 data points, denoted by x. Top row: uniform kernel. Bottom row: Gaussian kernel. Left column: bandwidth parameter $h=1$. Right column: bandwidth parameter $h=2$. Adapted from  http://en.wikipedia.org/wiki/Kernel_density_estimation .  \n",
    "Figure(s) generated by [Kernel_density_estimation](http://en.wikipedia.org/wiki/Kernel_density_estimation) [parzen_window_demo2.py](https://github.com/probml/pyprobml/blob/master/scripts/parzen_window_demo2.py) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcff7632",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Click me to run setup { display-mode: \"form\" }\n",
    "try:\n",
    "  if PYPROBML_SETUP_ALREADY_RUN:\n",
    "    print('skipping setup')\n",
    "except:\n",
    "  PYPROBML_SETUP_ALREADY_RUN = True\n",
    "  print('running setup...')\n",
    "  !git clone --depth 1 https://github.com/probml/pyprobml  /pyprobml &> /dev/null \n",
    "  %cd -q /pyprobml/scripts\n",
    "  import pyprobml_utils as pml\n",
    "  import colab_utils\n",
    "  import os\n",
    "  os.environ[\"PYPROBML\"] = \"..\" # one above current scripts directory\n",
    "  import google.colab \n",
    "  from google.colab.patches import cv2_imshow\n",
    "  %reload_ext autoreload \n",
    "  %autoreload 2\n",
    "  print('finished!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "471e8213",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run parzen_window_demo2.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "140f3ff4",
   "metadata": {},
   "source": [
    "## Figure 16.10:<a name='16.10'></a> <a name='kernelRegression'></a> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c6367a0",
   "metadata": {},
   "source": [
    "\n",
    " An example of kernel regression in 1d using a Gaussian kernel.  \n",
    "Figure(s) generated by [kernelRegressionDemo.py](https://github.com/probml/pyprobml/blob/master/scripts/kernelRegressionDemo.py) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcff7632",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Click me to run setup { display-mode: \"form\" }\n",
    "try:\n",
    "  if PYPROBML_SETUP_ALREADY_RUN:\n",
    "    print('skipping setup')\n",
    "except:\n",
    "  PYPROBML_SETUP_ALREADY_RUN = True\n",
    "  print('running setup...')\n",
    "  !git clone --depth 1 https://github.com/probml/pyprobml  /pyprobml &> /dev/null \n",
    "  %cd -q /pyprobml/scripts\n",
    "  import pyprobml_utils as pml\n",
    "  import colab_utils\n",
    "  import os\n",
    "  os.environ[\"PYPROBML\"] = \"..\" # one above current scripts directory\n",
    "  import google.colab \n",
    "  from google.colab.patches import cv2_imshow\n",
    "  %reload_ext autoreload \n",
    "  %autoreload 2\n",
    "  print('finished!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f302e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run kernelRegressionDemo.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c606560",
   "metadata": {},
   "source": [
    "## References:\n",
    " <a name='Duda01'>[DHS01]</a> R. O. Duda, P. E. Hart and D. G. Stork. \"Pattern Classification\". (2001). \n",
    "\n",
    "<a name='HastieBook'>[HTF09]</a> T. Hastie, R. Tibshirani and J. Friedman. \"The Elements of Statistical Learning\". (2009). \n",
    "\n",
    "<a name='Kaya2019'>[MH19]</a> K. Mahmut and B. HasanSakir. \"Deep Metric Learning: A Survey\". In: Symmetry (2019). \n",
    "\n",
    "<a name='Der2012'>[ML12]</a> D. Matthew and S. LawrenceK. \"Latent Coincidence Analysis: A Hidden Variable Model forDistance Metric Learning\". (2012). \n",
    "\n",
    "<a name='Do2019cvpr'>[Tha+19]</a> D. Thanh-Toan, T. Toan, R. Ian, K. Vijay, H. Tuan and C. Gustavo. \"A Theoretically Sound Upper Bound on the Triplet Loss forImproving the Efficiency of Deep Distance Metric Learning\". (2019). \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
